{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c7ccda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: C:\\Users\\dgner\\anaconda3\\lib\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n",
      "Average LPIPS value: 0.02506647292863239\n"
     ]
    }
   ],
   "source": [
    "import lpips\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load the pre-trained LPIPS model\n",
    "loss_fn = lpips.LPIPS(net='alex')\n",
    "\n",
    "# Path to the directories containing the images of the two datasets\n",
    "dataset1_dir = './data1'\n",
    "dataset2_dir = './data2'\n",
    "\n",
    "# Get the paths of the images in the two datasets\n",
    "dataset1_images = glob.glob(dataset1_dir + '/*.png')\n",
    "dataset2_images = glob.glob(dataset2_dir + '/*.png')\n",
    "\n",
    "# Calculate LPIPS for each pair of images\n",
    "total_lpips = 0.0\n",
    "num_pairs = min(len(dataset1_images), len(dataset2_images))\n",
    "\n",
    "if num_pairs > 0:\n",
    "    for i in range(num_pairs):\n",
    "        # Load images\n",
    "        image1 = cv2.imread(dataset1_images[i])\n",
    "        image2 = cv2.imread(dataset2_images[i])\n",
    "\n",
    "        # Convert images to PIL Image format\n",
    "        image1_pil = Image.fromarray(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "        image2_pil = Image.fromarray(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Resize images to a common size\n",
    "        transform = transforms.Resize((256, 256))\n",
    "        image1_resized = transform(image1_pil)\n",
    "        image2_resized = transform(image2_pil)\n",
    "\n",
    "        # Convert images to tensors\n",
    "        image1_tensor = transforms.ToTensor()(image1_resized)\n",
    "        image2_tensor = transforms.ToTensor()(image2_resized)\n",
    "\n",
    "        # Calculate LPIPS distance\n",
    "        lpips_distance = loss_fn(image1_tensor, image2_tensor).item()\n",
    "\n",
    "        # Accumulate the LPIPS values\n",
    "        total_lpips += lpips_distance\n",
    "\n",
    "    # Calculate the average LPIPS value\n",
    "    average_lpips = total_lpips / num_pairs\n",
    "\n",
    "    print(\"Average LPIPS value:\", average_lpips)\n",
    "else:\n",
    "    print(\"No image pairs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "00c68e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset resized successfully.\n",
      "Average SSIM value: 0.9564099817922215\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Path to the directory containing the original dataset\n",
    "original_dataset_dir = './data2'\n",
    "\n",
    "# Path to the directory where the resized dataset will be saved\n",
    "resized_dataset_dir = './data3'\n",
    "\n",
    "# Define the desired size for the resized images\n",
    "desired_size = (512, 512)\n",
    "\n",
    "# Create the resized dataset directory if it doesn't exist\n",
    "os.makedirs(resized_dataset_dir, exist_ok=True)\n",
    "\n",
    "# Get the list of files in the original dataset directory\n",
    "file_list = os.listdir(original_dataset_dir)\n",
    "\n",
    "# Resize each image in the dataset\n",
    "for file_name in file_list:\n",
    "    # Construct the paths for the original and resized images\n",
    "    original_image_path = os.path.join(original_dataset_dir, file_name)\n",
    "    resized_image_path = os.path.join(resized_dataset_dir, file_name)\n",
    "\n",
    "    # Load the original image\n",
    "    image = cv2.imread(original_image_path)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_image = cv2.resize(image, desired_size)\n",
    "\n",
    "    # Save the resized image\n",
    "    cv2.imwrite(resized_image_path, resized_image)\n",
    "\n",
    "print(\"Dataset resized successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "# Path to the directories containing the images of the two datasets\n",
    "dataset1_dir = './data1'\n",
    "dataset2_dir = './data3'\n",
    "\n",
    "# Get the paths of the images in the two datasets\n",
    "dataset1_images = glob.glob(dataset1_dir + '/*.png')\n",
    "dataset2_images = glob.glob(dataset2_dir + '/*.png')\n",
    "\n",
    "\n",
    "# Calculate SSIM for each pair of images\n",
    "total_ssim = 0.0\n",
    "num_pairs = min(len(dataset1_images), len(dataset2_images))\n",
    "\n",
    "if num_pairs > 0:\n",
    "    for i in range(num_pairs):\n",
    "        # Load images\n",
    "        image1 = cv2.imread(dataset1_images[i])\n",
    "        image2 = cv2.imread(dataset2_images[i])\n",
    "\n",
    "        # Check if images have the same shape\n",
    "        if image1.shape != image2.shape:\n",
    "            print(f\"Skipping image pair {dataset1_images[i]} and {dataset2_images[i]} due to different dimensions.\")\n",
    "            continue\n",
    "\n",
    "        # Resize images to a common size\n",
    "        common_size = (256, 256)\n",
    "        image1_resized = cv2.resize(image1, common_size)\n",
    "        image2_resized = cv2.resize(image2, common_size)\n",
    "\n",
    "        # Convert images to grayscale\n",
    "        image1_gray = cv2.cvtColor(image1_resized, cv2.COLOR_BGR2GRAY)\n",
    "        image2_gray = cv2.cvtColor(image2_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate SSIM\n",
    "        ssim_value = ssim(image1_gray, image2_gray, data_range=image2_gray.max() - image2_gray.min())\n",
    "\n",
    "        # Accumulate the SSIM values\n",
    "        total_ssim += ssim_value\n",
    "\n",
    "    # Calculate the average SSIM value\n",
    "    average_ssim = total_ssim / num_pairs\n",
    "\n",
    "    print(\"Average SSIM value:\", average_ssim)\n",
    "else:\n",
    "    print(\"No image pairs found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "34c69834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset resized successfully.\n",
      "Average PSNR: 35.08245133365495\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "\n",
    "# Path to the directory containing the original dataset\n",
    "original_dataset_dir = './data2'\n",
    "\n",
    "# Path to the directory where the resized dataset will be saved\n",
    "resized_dataset_dir = './data3'\n",
    "\n",
    "# Define the desired size for the resized images\n",
    "desired_size = (512, 512)\n",
    "\n",
    "# Create the resized dataset directory if it doesn't exist\n",
    "os.makedirs(resized_dataset_dir, exist_ok=True)\n",
    "\n",
    "# Get the list of files in the original dataset directory\n",
    "file_list = os.listdir(original_dataset_dir)\n",
    "\n",
    "# Resize each image in the dataset\n",
    "for file_name in file_list:\n",
    "    # Construct the paths for the original and resized images\n",
    "    original_image_path = os.path.join(original_dataset_dir, file_name)\n",
    "    resized_image_path = os.path.join(resized_dataset_dir, file_name)\n",
    "\n",
    "    # Load the original image\n",
    "    image = cv2.imread(original_image_path)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_image = cv2.resize(image, desired_size)\n",
    "\n",
    "    # Save the resized image\n",
    "    cv2.imwrite(resized_image_path, resized_image)\n",
    "\n",
    "print(\"Dataset resized successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "# Path to the directory containing the original images\n",
    "original_dir = './data1'\n",
    "\n",
    "# Path to the directory containing the reconstructed/resized images\n",
    "reconstructed_dir = './data3'\n",
    "\n",
    "# Get the list of files in the original images directory\n",
    "file_list = os.listdir(original_dir)\n",
    "\n",
    "# Calculate PSNR for each pair of images\n",
    "total_psnr = 0.0\n",
    "num_images = 0\n",
    "\n",
    "for file_name in file_list:\n",
    "    # Construct the paths for the original and reconstructed images\n",
    "    original_image_path = os.path.join(original_dir, file_name)\n",
    "    reconstructed_image_path = os.path.join(reconstructed_dir, file_name)\n",
    "\n",
    "    # Load the original and reconstructed images\n",
    "    image1 = cv2.imread(original_image_path)\n",
    "    image2 = cv2.imread(reconstructed_image_path)\n",
    "    \n",
    "     # Check if images have the same shape\n",
    "    if image1.shape != image2.shape:\n",
    "        print(f\"Skipping image pair {dataset1_images[i]} and {dataset2_images[i]} due to different dimensions.\")\n",
    "        continue\n",
    "\n",
    "    # Resize images to a common size\n",
    "    common_size = (256, 256)\n",
    "    image1_resized = cv2.resize(image1, common_size)\n",
    "    image2_resized = cv2.resize(image2, common_size)\n",
    "        \n",
    "\n",
    "    # Convert the images to grayscale\n",
    "    original_gray = cv2.cvtColor(image1_resized, cv2.COLOR_BGR2GRAY)\n",
    "    reconstructed_gray = cv2.cvtColor(image2_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate PSNR\n",
    "    psnr_value = peak_signal_noise_ratio(original_gray, reconstructed_gray, data_range=255)\n",
    "    total_psnr += psnr_value\n",
    "    num_images += 1\n",
    "\n",
    "# Calculate average PSNR\n",
    "average_psnr = total_psnr / num_images\n",
    "\n",
    "print(\"Average PSNR:\", average_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ce3b75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:02, ?it/s]\n",
      "0it [00:02, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID calculation error: array must not contain infs or NaNs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pytorch_fid import fid_score\n",
    "\n",
    "# Path to the directory containing real images\n",
    "real_images_dir = './data1'\n",
    "\n",
    "# Path to the directory containing generated images\n",
    "generated_images_dir = './data3'\n",
    "\n",
    "# Get the paths of the images in the two datasets\n",
    "dataset1_images = glob.glob(os.path.join(real_images_dir, '*.png'))\n",
    "dataset2_images = glob.glob(os.path.join(generated_images_dir, '*.png'))\n",
    "\n",
    "# Calculate FID\n",
    "try:\n",
    "    fid_value = fid_score.calculate_fid_given_paths(\n",
    "        dataset1_images, dataset2_images, device='cpu', dims=2048\n",
    "    )\n",
    "    print(\"FID value:\", fid_value)\n",
    "except ValueError as e:\n",
    "    print(\"FID calculation error:\", e)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred during FID calculation:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5b1b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b16a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
